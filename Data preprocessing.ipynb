{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "851691bf-3d70-4f24-bf0e-663a16153931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt  # Visualization\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import fairlearn\n",
    "from fairlearn.postprocessing import ThresholdOptimizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.impute import KNNImputer  # Using KNN for missing values\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load dataset\n",
    "data_folder = '~/Downloads/RDS Dataset/data'\n",
    "data = pd.read_csv(f'{data_folder}/training_v2.csv')\n",
    "\n",
    "# Define parameters\n",
    "test_ratio = 0.2\n",
    "validation_ratio = 0.4\n",
    "seed = 27\n",
    "missing_value_threshold = 0.75\n",
    "\n",
    "# Drop excessive missing data (only for hospital_death = 0)\n",
    "data = data.dropna(thresh=int(0.4 * len(data)), axis=1)\n",
    "\n",
    "# Remove fraction of rows where hospital_death == 0\n",
    "fraction = 0.8*(len(data[data['hospital_death'] == 0]) - len(data[data['hospital_death'] == 1]))/len(data) #*0.8 to maintain some of the difference\n",
    "data = data.drop(data[data['hospital_death'] == 0].sample(frac=fraction, random_state=seed).index)\n",
    "\n",
    "# Select features and target variable\n",
    "X = data.drop(['hospital_death', 'patient_id', 'encounter_id', 'hospital_id', 'icu_id',\n",
    "               'apache_4a_hospital_death_prob', 'apache_4a_icu_death_prob',\n",
    "               'apache_2_bodysystem'], axis=1)  # Drop identifiable features + target variable(s)\n",
    "y = data['hospital_death'].copy()\n",
    "y_apache = data['apache_4a_hospital_death_prob'].copy()\n",
    "\n",
    "# Split into training and testing\n",
    "X_train, X_test, y_train, y_test, y_apache_train, y_apache_test = train_test_split(\n",
    "    X, y, y_apache, test_size=test_ratio, random_state=seed)\n",
    "\n",
    "# Further split test set into validation and test\n",
    "X_val, X_test, y_val, y_test, y_apache_val, y_apache_test = train_test_split(\n",
    "    X_test, y_test, y_apache_test, test_size=validation_ratio, random_state=seed)\n",
    "\n",
    "# Drop columns with excessive missing values\n",
    "cols_to_drop = X_train.columns[X_train.isna().mean() > missing_value_threshold]\n",
    "X_train.drop(columns=cols_to_drop, inplace=True)\n",
    "X_val.drop(columns=cols_to_drop, inplace=True)\n",
    "X_test.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns\n",
    "numerical_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Initialize KNN imputer\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "X_train[numerical_features] = knn_imputer.fit_transform(X_train[numerical_features])\n",
    "X_val[numerical_features] = knn_imputer.transform(X_val[numerical_features])\n",
    "X_test[numerical_features] = knn_imputer.transform(X_test[numerical_features])\n",
    "\n",
    "# Fill missing categorical values with 'missing'\n",
    "X_train[categorical_features] = X_train[categorical_features].fillna('missing')\n",
    "X_val[categorical_features] = X_val[categorical_features].fillna('missing')\n",
    "X_test[categorical_features] = X_test[categorical_features].fillna('missing')\n",
    "\n",
    "# One-hot encoding for categorical features\n",
    "categorical_transformer = Pipeline(steps=[(\"encoder\", OneHotEncoder(drop=None, sparse_output=False, handle_unknown=\"ignore\"))])\n",
    "numerical_transformer = Pipeline(steps=[(\"imputer\", KNNImputer(n_neighbors=5))])\n",
    "\n",
    "# Define preprocessing pipeline\n",
    "preprocessing_pipeline = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, make_column_selector(dtype_include=object)),\n",
    "        ('num', numerical_transformer, make_column_selector(dtype_exclude=object))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit and transform datasets\n",
    "X_train = pd.DataFrame(preprocessing_pipeline.fit_transform(X_train), columns=preprocessing_pipeline.get_feature_names_out())\n",
    "X_val = pd.DataFrame(preprocessing_pipeline.transform(X_val), columns=preprocessing_pipeline.get_feature_names_out())\n",
    "X_test = pd.DataFrame(preprocessing_pipeline.transform(X_test), columns=preprocessing_pipeline.get_feature_names_out())\n",
    "\n",
    "# Fill missing values in target variable\n",
    "y_train.fillna(0, inplace=True)\n",
    "y_val.fillna(0, inplace=True)\n",
    "y_test.fillna(0, inplace=True)\n",
    "\n",
    "# Train a classifier\n",
    "clf = RandomForestClassifier(random_state=seed)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Apply Equalized Odds postprocessing to ensure fairness across ethnicity categories\n",
    "sensitive_feature = data['ethnicity'].copy()\n",
    "sensitive_feature = sensitive_feature.fillna('missing')\n",
    "\n",
    "threshold_optimizer = ThresholdOptimizer(estimator=clf, constraints=\"equalized_odds\", prefit=True)\n",
    "threshold_optimizer.fit(X_train, y_train, sensitive_features=sensitive_feature.loc[y_train.index])\n",
    "\n",
    "# Adjust predictions using the fairness-aware model\n",
    "y_train = threshold_optimizer.predict(X_train, sensitive_features=sensitive_feature.loc[y_train.index])\n",
    "y_val = threshold_optimizer.predict(X_val, sensitive_features=sensitive_feature.loc[y_val.index])\n",
    "y_test = threshold_optimizer.predict(X_test, sensitive_features=sensitive_feature.loc[y_test.index])\n",
    "\n",
    "# Convert NumPy arrays back to Pandas Series before saving\n",
    "y_train = pd.Series(y_train, index=X_train.index, name=\"hospital_death\")\n",
    "y_val = pd.Series(y_val, index=X_val.index, name=\"hospital_death\")\n",
    "y_test = pd.Series(y_test, index=X_test.index, name=\"hospital_death\")\n",
    "\n",
    "# Save processed datasets\n",
    "X_train.to_csv(f\"{data_folder}/X_train.csv\", index=False)\n",
    "X_val.to_csv(f'{data_folder}/X_val.csv', index=False)\n",
    "X_test.to_csv(f'{data_folder}/X_test.csv', index=False)\n",
    "y_train.to_csv(f'{data_folder}/y_train.csv', index=False)\n",
    "y_val.to_csv(f'{data_folder}/y_val.csv', index=False)\n",
    "y_test.to_csv(f'{data_folder}/y_test.csv', index=False)\n",
    "y_apache_test.to_csv(f'{data_folder}/y_apache_test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce377573-3b48-4682-a248-8c6d1df591fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
